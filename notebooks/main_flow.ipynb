{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89bed027",
   "metadata": {},
   "source": [
    "# Project\n",
    " - 2 CLUSTERING AND 1 DIMENSION REDUCTION METHOD NOT LEARNT IN THE COURSE \n",
    "\n",
    "## Static Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "26f5a82e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-22T16:02:20.875284Z",
     "start_time": "2023-02-22T16:02:20.867958Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from tqdm import tqdm\n",
    "import sklearn.metrics as metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering, Birch\n",
    "from sklearn.manifold import TSNE, SpectralEmbedding, Isomap, MDS\n",
    "from fcmeans import FCM\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.svm import OneClassSVM\n",
    "import json\n",
    "import os\n",
    "import ast\n",
    "import pandas as pd\n",
    "import random\n",
    "import networkx as nx\n",
    "from community import community_louvain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cce239fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-22T16:42:14.039987Z",
     "start_time": "2023-02-22T16:42:08.084290Z"
    }
   },
   "outputs": [],
   "source": [
    "data_path=\"../data/fma_metadata\"\n",
    "features = pd.read_csv(os.path.join(data_path, \"features.csv\"), index_col=0, header=[0, 1, 2])\n",
    "tracks = pd.read_csv(os.path.join(data_path, \"tracks.csv\"), index_col=0, header=[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1f6f1a2c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-22T16:43:36.876600Z",
     "start_time": "2023-02-22T16:43:36.862864Z"
    }
   },
   "outputs": [],
   "source": [
    "COLUMNS = [('track', 'genre_top'), ('track', 'license'),\n",
    "           ('album', 'type')]\n",
    "for column in COLUMNS:\n",
    "    tracks[column] = tracks[column].astype('category')\n",
    "X, y = features, tracks[COLUMNS]  # X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ac0fef7b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-22T16:46:09.987795Z",
     "start_time": "2023-02-22T16:46:09.975460Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('track', 'genre_top') 16\n",
      "('track', 'license') 113\n",
      "('album', 'type') 5\n"
     ]
    }
   ],
   "source": [
    "for column in y:\n",
    "    print(column, y[column].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b4004d4e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-22T17:38:31.316545Z",
     "start_time": "2023-02-22T17:38:31.311365Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(106574, 518)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedab5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_algo = [Kmean(), ...]\n",
    "dim_reduction_algo = [PCA(), ICA(),...]\n",
    "dimentions_options = [10, 50, 200, None]\n",
    "num_clusters_options = [2, 4, 6, 8, 10, 15, 20]\n",
    "best_config_by_clustering = dict()\n",
    "for clutering_algo in scores:\n",
    "    for dim_reduction in dim_reduction_algo:\n",
    "        max_score = 0\n",
    "        dim_reduction_distrabutions = defualtdict(list)\n",
    "        for dim_num in dimentions_options:\n",
    "            for cluster_num in num_clusters_options:\n",
    "                scores = []\n",
    "                for cv_data in cvs:\n",
    "                    new_data = dim_reduction(cv_data, dim_num)\n",
    "                    labdels = clutering(new_data)\n",
    "                    scores.append(sillout(labels))\n",
    "                curr_score = np.mean(scores)\n",
    "                if curr_score > max_score:\n",
    "                    max_score = curr_score\n",
    "                    dim_reduction_distrabutions[dim_reduction, \"scores\"] = scores\n",
    "                    dim_reduction_distrabutions[dim_reduction, \"mean_score\"] = max_score\n",
    "                    dim_reduction_distrabutions[dim_reduction, \"max_dim_num\"] = dim_num\n",
    "                    dim_reduction_distrabutions[dim_reduction, \"max_cluster_num\"] = cluster_num\n",
    "                    # not really metters\n",
    "\n",
    "    p_value = anova(dim_reduction_distrabutions.values())\n",
    "    if p_value < 0.05:\n",
    "        dim_reduction1, dim_reduction2 = arg_n_top(n=2, dim_reduction_distrabutions[:, \"mean_score\"])\n",
    "        t_p_value = t_test(dim_reduction_distrabutions[dim_reduction1, \"scores\"], dim_reduction_distrabutions[dim_reduction2, \"scores\"])\n",
    "        if t_p_value < 0.05:\n",
    "            best_dim_reduction = argmax(dim_reduction_distrabutions[:, \"mean_score\"])\n",
    "            best_config_by_clustering[clutering_algo] = best_dim_reduction # reduction_algo,  max_dim_num, max_cluster_num\n",
    "            # algo reduction , dimention, n_cluster\n",
    "        else:\n",
    "            print(\"same same but different\")\n",
    "    else:\n",
    "        print(\"same same but different\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33af1973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hidden variables with the best clustering and dim_reduction\n",
    "for external_var in external_vars:\n",
    "    all_mi = dict()\n",
    "    for clustering_algo, best_config in best_config_by_clustering.items():\n",
    "        for cv in cvs:\n",
    "            labels = clustering_algo(best_config, cv)\n",
    "            all_mi[external_var].append(MI(labels, external_var))\n",
    "    anova(all_mi.values())\n",
    "    # t-test with the top 2\n",
    "    # yield best_cluster_algo_per_external_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704359da",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mi = dict()\n",
    "for clustering_algo, best_config in best_config_by_clustering.items():\n",
    "    for external_var in external_vars:\n",
    "        for cv in cvs:\n",
    "            # change in best_config max_cluster_num to len(np.unique(external_var))\n",
    "            labels = clustering_algo(best_config, cv)\n",
    "            all_mi[clustering_algo, external_var].append(MI(labels, external_var))\n",
    "    anova(all_mi[clustering_algo, :].values())\n",
    "    # t-test with the top 2\n",
    "    # yield best_cluster_algo_per_external_var"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2885f710",
   "metadata": {},
   "source": [
    "### Cluster the remaining columns, and explain what are is the best clustering method.\n",
    "- silhouette_score\n",
    "- elbow method\n",
    "- k-fold cross validation on silhouette_score or Matual information with - kruskal wallis or anova"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcdbb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_model_by_silhouette(models, X)\n",
    "    for model in models:\n",
    "        labels = model.fit_predict(X)\n",
    "        scores.append(metrics.silhouette_score(X, labels))\n",
    "    plt.plot(models, scores)\n",
    "    plt.title(f\"silhouette_score diffrent models - {model_name}\")\n",
    "    plt.xlabel(\"models\")\n",
    "    plt.ylabel(\"Silhouette Score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f908f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "52a0a632",
   "metadata": {},
   "source": [
    "### Fuzzy C-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a6931b",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = FCM(n_clusters=2)\n",
    "my_model.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4af32d6",
   "metadata": {},
   "source": [
    "#### K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1a4599",
   "metadata": {},
   "outputs": [],
   "source": [
    "KMeans(k, n_init=\"auto\", random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8725b031",
   "metadata": {},
   "source": [
    "#### Gaussian-Mixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52861b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "GaussianMixture(k, max_iter=3000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28878168",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-03T13:25:56.391773Z",
     "start_time": "2023-02-03T13:25:56.384378Z"
    }
   },
   "source": [
    "#### Hierarchical Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f965558d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.cluster.hierarchy as sch # importing scipy.cluster.hierarchy for dendrogram\n",
    "dendrogram = sch.dendrogram(sch.linkage(X, method = 'ward')) # finding the optimal number of clusters using dendrogram\n",
    "plt.title('Dendrogram') # title of the dendrogram\n",
    "plt.xlabel('Customers') # label of the x-axis\n",
    "plt.ylabel('Euclidean distances') # label of the y-axis\n",
    "plt.show() # show the dendrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4194de76",
   "metadata": {},
   "outputs": [],
   "source": [
    "Agg_hc = AgglomerativeClustering(n_clusters = 5, affinity = 'euclidean', linkage = 'ward')\n",
    "y_hc = Agg_hc.fit_predict(newData)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e464f31",
   "metadata": {},
   "source": [
    "#### Birch - didn't learned in the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2950c867",
   "metadata": {},
   "outputs": [],
   "source": [
    "Birch(n_clusters=k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ddeb56",
   "metadata": {},
   "source": [
    "#### Dbscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fcc658",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_best_dbscan_params(clean_X: np.ndarray, min_samples: int):\n",
    "    range_eps = np.linspace(0.1, 10, 20)\n",
    "    scores = []\n",
    "    for eps in range_eps:\n",
    "        model = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "        good_labels = model.fit_predict(clean_X)\n",
    "        noisy_data_count = len(good_labels[good_labels == -1])\n",
    "        if noisy_data_count > good_labels.shape[0] * 0.5 or len(np.unique(good_labels)) < 3:\n",
    "            scores.append(0)\n",
    "            continue\n",
    "        print(f\"noisy data count with eps={eps}: {noisy_data_count}\")\n",
    "        try:\n",
    "            score = metrics.silhouette_score(clean_X, good_labels)\n",
    "        except:\n",
    "            score = 0\n",
    "        scores.append(score)\n",
    "    plt.plot(range_eps, scores)\n",
    "    plt.show()\n",
    "    return range_eps[np.argmax(scores)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacac3f1",
   "metadata": {},
   "source": [
    "#### SpectralClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1cfae74",
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering = SpectralClustering(n_clusters=2,assign_labels='discretize',random_state=0).fit_predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd9f26c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0d1db6ca",
   "metadata": {},
   "source": [
    "### Associate the clusters with the ground truth, and explain what external variable is best associated with clusters, and what clustering method best associates with the outside variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ceb9978",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3c680268",
   "metadata": {},
   "source": [
    "### Find anomalies in the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257e5e45",
   "metadata": {},
   "source": [
    "### using DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf390fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "labels = model.fit_predict(X)\n",
    "labels[labels == -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3080421d",
   "metadata": {},
   "source": [
    "### using isolation forest\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.IsolationForest.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8166a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = IsolationForest(random_state=0).fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2c85c7",
   "metadata": {},
   "source": [
    "### one classs svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37141510",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_class_svm = OneClassSVM(nu=0.01, kernel = 'rbf', gamma = 'auto').fit(X_train)\n",
    "prediction = one_class_svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5baa46",
   "metadata": {},
   "source": [
    "### test whether anomalies are associated with any of the external variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5992ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e7e6193c",
   "metadata": {},
   "source": [
    "### check if anomaly detection improves the clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fc8955",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8b0c30ee",
   "metadata": {},
   "source": [
    "### Reduce the dimension of the data and propose a visualization that best characterize the clusters associated with the external variables. Please find a smart presentation scheme to highlight both clusters and variables.\n",
    "\n",
    "- TSNE\n",
    "- Isomap\n",
    "- MDS\n",
    "- PCA\n",
    "- SpectralEmbedding\n",
    "- PCoA\n",
    "- LLE\n",
    "- UMAP\n",
    "- AutoEncoders\n",
    "- ICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79ccf593",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-03T13:48:58.474377Z",
     "start_time": "2023-02-03T13:48:58.460546Z"
    }
   },
   "outputs": [],
   "source": [
    "def reduce_dimension(X):\n",
    "    models = [TSNE(n_components=2), Isomap(n_components=2), MDS(n_components=2), SpectralEmbedding(n_components=2)]\n",
    "    fig, axs = plt.subplots(nrows=len(models), ncols=1, figsize=(8, 8))\n",
    "    fig.tight_layout()\n",
    "    for i, model in tqdm(enumerate(models)):\n",
    "        X_embedded_tsne = model.fit_transform(X)\n",
    "        axs[i].scatter(X_embedded_tsne[:, 0], X_embedded_tsne[:, 1], s=40, cmap='viridis')\n",
    "        axs[i].set_title(f\"{model} dimensionality reduction\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356a8657",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4d7342",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7f219202",
   "metadata": {},
   "source": [
    "## Dynamic Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e055170b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dynamic_dataset(data_path=\"data/driftdataset\"):\n",
    "    dfs = []\n",
    "    for filename in os.listdir(data_path):\n",
    "        with open(os.path.join(data_path, filename), \"r\") as file:\n",
    "            df = pd.read_csv(\n",
    "                file,\n",
    "                sep=\"\\s+\",\n",
    "                skiprows=1,\n",
    "                usecols=[0, 7],\n",
    "                names=['TIME', 'XGSM']\n",
    "            )\n",
    "            dfs.append(df)\n",
    "    return pd.concat(dfs, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d98aba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-03T13:41:13.442198Z",
     "start_time": "2023-02-03T13:41:13.436848Z"
    }
   },
   "source": [
    "### Hidden Markov model for time series\n",
    "https://rubikscode.net/2021/09/06/stock-price-prediction-using-hidden-markov-model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63959d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "99de5e94",
   "metadata": {},
   "source": [
    "## Graph Based Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fe0967",
   "metadata": {},
   "source": [
    "### Louvainâ€™s Algorithm for Community Detection\n",
    "https://github.com/taynaud/python-louvain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cb822f61",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-22T16:09:09.182601Z",
     "start_time": "2023-02-22T16:07:26.069402Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'_AxesStack' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m graph, target \u001b[38;5;241m=\u001b[39m load_graph_dataset()\n\u001b[1;32m     14\u001b[0m pos \u001b[38;5;241m=\u001b[39m nx\u001b[38;5;241m.\u001b[39mspring_layout(graph)\n\u001b[0;32m---> 15\u001b[0m \u001b[43mnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m75\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.8\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/networkx/drawing/nx_pylab.py:115\u001b[0m, in \u001b[0;36mdraw\u001b[0;34m(G, pos, ax, **kwds)\u001b[0m\n\u001b[1;32m    113\u001b[0m cf\u001b[38;5;241m.\u001b[39mset_facecolor(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ax \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 115\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mcf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_axstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    116\u001b[0m         ax \u001b[38;5;241m=\u001b[39m cf\u001b[38;5;241m.\u001b[39madd_axes((\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: '_AxesStack' object is not callable"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def load_graph_dataset(data_path=\"../data/deezer_ego_nets\"):\n",
    "    with open(os.path.join(data_path, \"deezer_edges.json\")) as f:\n",
    "        graph = nx.MultiGraph({\n",
    "            node: [element[1] for element in neighbors]\n",
    "            for node, neighbors in json.load(f).items()\n",
    "        })\n",
    "    target = pd.read_csv(os.path.join(data_path, \"deezer_target.csv\"))\n",
    "    print(graph.edges, target)\n",
    "    return graph, target\n",
    "\n",
    "\n",
    "n = 500\n",
    "graph, target = load_graph_dataset()\n",
    "pos = nx.spring_layout(graph)\n",
    "nx.draw(graph, pos, node_size = 75, alpha = 0.8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eac8b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "comms = community_louvain.best_partition(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43f50d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_coms = np.unique(list(comms.values()))\n",
    "cmap = {\n",
    "    0 : 'maroon',\n",
    "    1 : 'teal',\n",
    "    2 : 'black', \n",
    "    3 : 'orange',\n",
    "    4 : 'green',\n",
    "    5 : 'yellow'\n",
    "}\n",
    "\n",
    "node_cmap = [cmap[v] for _,v in comms.items()]\n",
    "\n",
    "pos = nx.spring_layout(G)\n",
    "nx.draw(G, pos, node_size = 75, alpha = 0.8, node_color=node_cmap)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691628ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
